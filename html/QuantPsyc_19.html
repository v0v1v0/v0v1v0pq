<div class="container">

<table style="width: 100%;"><tr>
<td>powerF</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2> Power in F distribution</h2>

<h3>Description</h3>

<p>Computes power (1 - beta) to detect an effect with a given effect size, sample size (df) and specified alpha (significance) level. 
</p>


<h3>Usage</h3>

<pre><code class="language-R">powerF(PV, df2, df1 = 1, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>PV</code></td>
<td>
<p>Percent of variance accounted for by effect.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df2</code></td>
<td>
<p>Denominator Degrees of Freedom for a given model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df1</code></td>
<td>
<p>Numerator Degrees of Freedom for a given model </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>Significance level for desired effect</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Murphy &amp; Myors (2004) detail the use of a similar function and the notion that most distributions can be converted to F. Therefore, they argue that the F distribution is the most versatile in computing power. Typically, alpha is set at .05 (default). Users will likely find conversions of various distributions to F corresponding to a df1=1 (default). Therefore, users can manipulate df2 based on their model to estiamte sample size needs. Likewise, one may begin with a given sample size (i.e., df2) and manipulate PV (effect size) to iteratively determine what power their study is likely to detect. Conventions maintain that .80 is a sufficient target, and that no study shold be designed with power = .5 or less. 
</p>


<h3>Value</h3>

<p>A numeric value representing the power to detect the effect
</p>


<h3>Warning </h3>

<p>It is critical that the user correctly specify the model for which the effect is obtained. For instance, if a single coeficient from a regression model is the object of inquiry (e.g., interaction effect in moderation model), the DF should reflect that effect and not the overall model, which also contains the 'main effects'. </p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Murphy, K. R., &amp; Myors, B. (2004). <em>Statistical power analysis: A simple and general model for traditional and modern hypothesis tests (2nd ed.).</em> Mahwah, NJ: Lawrence Erlbaum Associates.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# Simulated TRA example
data(tra)
lm1 &lt;- lm (attitudes ~ beliefs*values, tra)
summary(lm1) 
# power to detect the interaction effect, where df1 = 1 and df2 = n-k-1 = 996
# PV = t^2/(t^2+df2) = .1863
powerF(.1863, 996)

# Estimate sample size needed to detect interaction effect with PV = .01 and power = .8
powerF(.01, 200)  # too low
powerF(.01, 1000) # too high
powerF(.01, (800-3-1))  # just right: n=800 - k=3 - 1

</code></pre>


</div>