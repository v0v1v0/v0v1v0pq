<div class="container">

<table style="width: 100%;"><tr>
<td>qgcomp.zi.boot</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Quantile g-computation for zero-inflated count outcomes</h2>

<h3>Description</h3>

<p>This function estimates a linear dose-response parameter representing a one quantile
increase in a set of exposures of interest for zero-inflated count outcomes. This function is
limited to linear and additive
effects of individual components of the exposure. This model estimates the parameters of a marginal
structural zero-inflated count model (MSM) based on g-computation with quantized exposures.
Note: this function
allows linear and non-additive effects of individual components of the exposure, as well as
non-linear joint effects of the mixture via polynomial basis functions, which increase the
computational computational burden due to the need for non-parametric bootstrapping.
</p>


<h3>Usage</h3>

<pre><code class="language-R">qgcomp.zi.boot(
  f,
  data,
  expnms = NULL,
  q = 4,
  breaks = NULL,
  id = NULL,
  weights,
  alpha = 0.05,
  B = 200,
  degree = 1,
  seed = NULL,
  bayes = FALSE,
  parallel = FALSE,
  MCsize = 10000,
  msmcontrol = zimsm_fit.control(),
  parplan = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>f</code></td>
<td>
<p>R style formula</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>data frame</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>expnms</code></td>
<td>
<p>character vector of exposures of interest</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>q</code></td>
<td>
<p>NULL or number of quantiles used to create quantile indicator variables
representing the exposure variables. If NULL, then gcomp proceeds with un-transformed
version of exposures in the input datasets (useful if data are already transformed,
or for performing standard g-computation)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>breaks</code></td>
<td>
<p>(optional) NULL, or a list of (equal length) numeric vectors that
characterize the minimum value of each category for which to
break up the variables named in expnms. This is an alternative to using 'q'
to define cutpoints.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>id</code></td>
<td>
<p>(optional) NULL, or variable name indexing individual units of
observation (only needed if analyzing data with multiple observations per
id/cluster)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>"case weights" - passed to the "weight" argument of
<code>zeroinfl</code>. NOTE - this does not work with parallel=TRUE!</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>alpha level for confidence limit calculation</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>B</code></td>
<td>
<p>integer: number of bootstrap iterations (this should typically be &gt;=200,
though it is set lower in examples to improve run-time).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>degree</code></td>
<td>
<p>polynomial basis function for marginal model (e.g. degree = 2
allows that the relationship between the whole exposure mixture and the outcome
is quadratic.)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>integer or NULL: random number seed for replicable bootstrap results</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bayes</code></td>
<td>
<p>not currently implemented.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parallel</code></td>
<td>
<p>use (safe) parallel processing from the future and future.apply packages</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>MCsize</code></td>
<td>
<p>integer: sample size for simulation to approximate marginal
zero inflated model parameters. This can be left small for testing, but should be as large
as needed to reduce simulation error to an acceptable magnitude (can compare psi coefficients for
linear fits with qgcomp.zi.noboot to gain some intuition for the level of expected simulation
error at a given value of MCsize)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>msmcontrol</code></td>
<td>
<p>named list from <code>zimsm_fit.control</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parplan</code></td>
<td>
<p>(logical, default=FALSE) automatically set future::plan to plan(multisession) (and set to existing plan, if any, after bootstrapping)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>arguments to glm (e.g. family)</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Zero-inflated count models allow excess zeros in standard count outcome (e.g.
Poisson distributed outcomes). Such models have two components: 1 ) the probability of
arising from a degenerate distribution at zero (versus arising from a count distribution)
and 2 ) the rate parameter of a count distribution. Thus, one has the option of allowing
exposure and covariate effects on the zero distribution, the count distribution, or both.
The zero distribution parameters correspond to log-odds ratios for the probability of arising
from the zero distribution. Count distribution parameters correspond to log-rate-ratio parameters.
Test statistics and confidence intervals are based on
a non-parametric bootstrap, using the standard deviation of the bootstrap
estimates to estimate the standard error. The bootstrap standard error is
then used to estimate Wald-type confidence intervals. Note that no bootstrapping
is done on estimated quantiles of exposure, so these are treated as fixed
quantities.
</p>
<p>Of note, this function yields marginal estimates of the expected outcome under
values of the joint exposure quantiles (e.g. the expected outcome if all exposures
are below the 1st quartile). These outcomes can be used to derive estimates of the
effect on the marginal expectation of the outcome, irrespective of zero-inflated/count
portions of the statistical model.
</p>
<p>Estimates correspond to the average expected change in the
(log) outcome per quantile increase in the joint exposure to all exposures
in ‘expnms’. Test statistics and confidence intervals are based on
a non-parametric bootstrap, using the standard deviation of the bootstrap
estimates to estimate the standard error. The bootstrap standard error is
then used to estimate Wald-type confidence intervals. Note that no bootstrapping
is done on estimated quantiles of exposure, so these are treated as fixed
quantities
</p>


<h3>Value</h3>

<p>a qgcompfit object, which contains information about the effect
measure of interest (psi) and associated variance (var.psi), as well
as information on the model fit (fit) and information on the
marginal structural model (msmfit) used to estimate the final effect
estimates.
</p>


<h3>See Also</h3>

<p>Other qgcomp_methods: 
<code>qgcomp.cch.noboot()</code>,
<code>qgcomp.cox.boot()</code>,
<code>qgcomp.cox.noboot()</code>,
<code>qgcomp.glm.boot()</code>,
<code>qgcomp.glm.noboot()</code>,
<code>qgcomp.hurdle.boot()</code>,
<code>qgcomp.hurdle.noboot()</code>,
<code>qgcomp.multinomial.boot()</code>,
<code>qgcomp.multinomial.noboot()</code>,
<code>qgcomp.partials()</code>,
<code>qgcomp.zi.noboot()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(50)
n=100
dat &lt;- data.frame(y=rbinom(n, 1, 0.5)*rpois(n, 1.2), x1=runif(n), x2=runif(n), z=runif(n))
# poisson count model, mixture in both portions
## Not run: 
# warning: the examples below can take a long time to run
res = qgcomp.zi.boot(f=y ~ x1 + x2 | x1 + x2, expnms = c('x1', 'x2'), 
    data=dat, q=4, dist="poisson", B=1000, MCsize=10000, parallel=TRUE, parplan=TRUE)
qgcomp.zi.noboot(f=y ~ x1 + x2 | x1 + x2, expnms = c('x1', 'x2'), 
    data=dat, q=4, dist="poisson")
res

# accuracy for small MCsize is suspect (compare coefficients between boot/noboot versions), 
# so re-check with MCsize set to larger value (this takes a long time to run)
res2 = qgcomp.zi.boot(f=y ~ x1 + x2 | x1 + x2, expnms = c('x1', 'x2'), 
    data=dat, q=4, dist="poisson", B=1000, MCsize=50000, parallel=TRUE, parplan=TRUE)
 res2
plot(density(res2$bootsamps[4,]))

# negative binomial count model, mixture and covariate in both portions
qgcomp.zi.boot(f=y ~ z + x1 + x2 | z + x1 + x2, expnms = c('x1', 'x2'), 
   data=dat, q=4, dist="negbin", B=10, MCsize=10000) 
   
# weighted analysis (NOTE THIS DOES NOT WORK WITH parallel=TRUE!)
dat$w = runif(n)*5
qgcomp.zi.noboot(f=y ~ z + x1 + x2 | x1 + x2, expnms = c('x1', 'x2'), 
    data=dat, q=4, dist="poisson", weights=w)
# Expect this:     
# Warning message:
# In eval(family$initialize) : non-integer #successes in a binomial glm!
qgcomp.zi.boot(f=y ~ x1 + x2 | x1 + x2, expnms = c('x1', 'x2'), 
    data=dat, q=4, dist="poisson", B=5, MCsize=50000, parallel=FALSE, weights=w)
# Log rr per one IQR change in all exposures (not on quantile basis)
dat$x1iqr &lt;- dat$x1/with(dat, diff(quantile(x1, c(.25, .75))))
dat$x2iqr &lt;- dat$x2/with(dat, diff(quantile(x2, c(.25, .75))))
# note that I(x&gt;...) now operates on the untransformed value of x,
# rather than the quantized value
res2 = qgcomp.zi.boot(y ~ z + x1iqr + x2iqr + I(x2iqr&gt;0.1) + I(x2&gt;0.4) + I(x2&gt;0.9) | x1iqr + x2iqr, 
                   family="binomial", expnms = c('x1iqr', 'x2iqr'), data=dat, q=NULL, B=2, 
                   degree=2, MCsize=200, dist="poisson")
res2

## End(Not run)
</code></pre>


</div>