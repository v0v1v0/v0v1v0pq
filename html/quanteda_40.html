<div class="container">

<table style="width: 100%;"><tr>
<td>tokenize_custom</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Customizable tokenizer</h2>

<h3>Description</h3>

<p>Allows users to tokenize texts using customized boundary rules. See the <a href="https://unicode-org.github.io/icu/userguide/boundaryanalysis/break-rules.html">ICU website</a>
for how to define boundary rules.
</p>
<p>Tools for custom word and sentence breakrules, to retrieve, set, or reset
them to package defaults.
</p>


<h3>Usage</h3>

<pre><code class="language-R">tokenize_custom(x, rules)

breakrules_get(what = c("word", "sentence"))

breakrules_set(x, what = c("word", "sentence"))

breakrules_reset(what = c("word", "sentence"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>character vector for texts to tokenize</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rules</code></td>
<td>
<p>a list of rules for rule-based boundary detection</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>what</code></td>
<td>
<p>character; which set of rules to return, one of <code>"word"</code> or
<code>"sentence"</code></p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The package contains internal sets of rules for word and sentence
breaks, which are lists
of rules for word and sentence boundary detection. <code>base</code> is copied from
the ICU library. Other rules are created by the package maintainers in
<code>system.file("breakrules/breakrules_custom.yml")</code>.
</p>
<p>This function allows modification of those rules, and applies them as a new
tokenizer.
</p>
<p>Custom word rules:
</p>

<dl>
<dt><code>base</code></dt>
<dd>
<p>ICU's rules for detecting word/sentence boundaries</p>
</dd>
<dt><code>keep_hyphens</code></dt>
<dd>
<p>quanteda's rule for preserving hyphens</p>
</dd>
<dt><code>keep_url</code></dt>
<dd>
<p>quanteda's rule for preserving URLs</p>
</dd>
<dt><code>keep_email</code></dt>
<dd>
<p>quanteda's rule for preserving emails</p>
</dd>
<dt><code>keep_tags</code></dt>
<dd>
<p>quanteda's rule for preserving tags</p>
</dd>
<dt><code>split_elisions</code></dt>
<dd>
<p>quanteda's rule for splitting elisions</p>
</dd>
<dt><code>split_tags</code></dt>
<dd>
<p>quanteda's rule for splitting tags</p>
</dd>
</dl>
<h3>Value</h3>

<p><code>tokenize_custom()</code> returns a list of characters containing tokens.
</p>
<p><code>breakrules_get()</code> returns the existing break rules as a list.
</p>
<p><code>breakrules_set()</code> returns nothing but reassigns the global
breakrules to <code>x</code>.
</p>
<p><code>breakrules_reset()</code> returns nothing but reassigns the global
breakrules to the system defaults.  These rules are defined in
<code>system.file("breakrules/")</code>.
</p>


<h3>Source</h3>

<p><a href="https://raw.githubusercontent.com/unicode-org/icu/main/icu4c/source/data/brkitr/rules/word.txt">https://raw.githubusercontent.com/unicode-org/icu/main/icu4c/source/data/brkitr/rules/word.txt</a>
</p>
<p><a href="https://raw.githubusercontent.com/unicode-org/icu/main/icu4c/source/data/brkitr/rules/sent.txt">https://raw.githubusercontent.com/unicode-org/icu/main/icu4c/source/data/brkitr/rules/sent.txt</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">lis &lt;- tokenize_custom("a well-known http://example.com", rules = breakrules_get("word"))
tokens(lis, remove_separators = TRUE)
breakrules_get("word")
breakrules_get("sentence")

brw &lt;- breakrules_get("word")
brw$keep_email &lt;- "@[a-zA-Z0-9_]+"
breakrules_set(brw, what = "word")
breakrules_reset("sentence")
breakrules_reset("word")
</code></pre>


</div>