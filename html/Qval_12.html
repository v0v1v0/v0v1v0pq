<div class="container">

<table style="width: 100%;"><tr>
<td>validation</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Perform Q-matrix validation methods</h2>

<h3>Description</h3>

<p>This function uses generalized Q-matrix validation methods to validate the Q-matrix,
including commonly used methods such as GDI (de la Torre, &amp; Chiu, 2016; Najera, Sorrel,
&amp; Abad, 2019; Najera et al., 2020), Wald (Ma, &amp; de la Torre, 2020), Hull (Najera et al.,
2021), and MLR-B (Tu et al., 2022). It supports different iteration methods (test
level or item level; Najera et al., 2020; Najera et al., 2021; Tu et al., 2022) and
can apply various attribute search methods (ESA, SSA, PAA; de la Torre, 2008; Terzi, &amp;
de la Torre, 2018). More see details.
</p>


<h3>Usage</h3>

<pre><code class="language-R">validation(
  Y,
  Q,
  CDM.obj = NULL,
  par.method = "EM",
  mono.constraint = TRUE,
  model = "GDINA",
  method = "GDI",
  search.method = "PAA",
  maxitr = 1,
  iter.level = "test",
  eps = 0.95,
  alpha.level = 0.05,
  criter = "PVAF",
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>A required <code>N</code> × <code>I</code> matrix or data.frame consisting of the responses of <code>N</code> individuals
to <code>I</code> items. Missing values need to be coded as <code>NA</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Q</code></td>
<td>
<p>A required binary <code>I</code> × <code>K</code> containing the attributes not required or required, 0 or 1,
to master the items. The <code>i</code>th row of the matrix is a binary indicator vector indicating which
attributes are not required (coded by 0) and which attributes are required (coded by 1) to
master item <code>i</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>CDM.obj</code></td>
<td>
<p>An object of class <code>CDM.obj</code>. When it is not NULL, it enables rapid verification
of the Q-matrix without the need for parameter estimation. @seealso <code>CDM</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>par.method</code></td>
<td>
<p>Type of mtehod to estimate CDMs' parameters; one out of <code>"EM"</code>, <code>"BM"</code>. Default = <code>"EM"</code>
However, <code>"BM"</code> is only avaible when <code>method = "GDINA"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mono.constraint</code></td>
<td>
<p>Logical indicating whether monotonicity constraints should be fulfilled in estimation.
Default = <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>Type of model to fit; can be <code>"GDINA"</code>, <code>"LCDM"</code>, <code>"DINA"</code>, <code>"DINO"</code>
, <code>"ACDM"</code>, <code>"LLM"</code>, or <code>"rRUM"</code>. Default = <code>"GDINA"</code>.
@seealso <code>CDM</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>The methods to validata Q-matrix, can be <code>"GDI"</code>, <code>"Wald"</code>, <code>"Hull"</code>, and
<code>"MLR-B"</code>. The <code>"model"</code> must be <code>"GDINA"</code> when <code>method = "Wald"</code>.
Default = <code>"GDI"</code>. See details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>search.method</code></td>
<td>
<p>Character string specifying the search method to use during validation.
</p>

<dl>
<dt>"SSA"</dt>
<dd>
<p>for sequential search algorithm (see de la Torre, 2008; Terzi &amp; de la Torre, 2018). 
This option can be used when the <code>method</code> is <code>"GDI"</code>, <code>"Hull"</code> or <code>"MLR-B"</code>.</p>
</dd>
<dt>"ESA"</dt>
<dd>
<p>for exhaustive search algorithm. This option can be used when the <code>method</code> is 
any of <code>"GDI"</code>, <code>"Hull"</code>, or <code>"MLR-B"</code>.</p>
</dd>
<dt>"PAA"</dt>
<dd>
<p>for priority attribute algorithm.
This is the default option and can be used when the <code>method</code> is any of <code>"GDI"</code>, <code>"Wald"</code>, <code>"Hull"</code>, or <code>"MLR-B"</code>.</p>
</dd>
<dt>"stepwise"</dt>
<dd>
<p>only for the <code>"Wald"</code></p>
</dd>
<dt>"forward"</dt>
<dd>
<p>only for the <code>"Wald"</code></p>
</dd>
</dl>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxitr</code></td>
<td>
<p>Number of max iterations. Default = <code>1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iter.level</code></td>
<td>
<p>Can be <code>"item"</code> level or <code>"test"</code> level. Default = <code>"test"</code>. Only <code>"test"</code> 
is available When method = <code>"Wald"</code> or <code>"MLR-B"</code>. See details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p>Cut-off points of <code class="reqn">PVAF</code>, will work when the method is <code>"GDI"</code> or <code>"Wald"</code>.
Default = <code>0.95</code>. See details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha.level</code></td>
<td>
<p>alpha level for the wald test. Default = <code>0.05</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>criter</code></td>
<td>
<p>The kind of fit-index value, can be <code class="reqn">R^2</code> for <code class="reqn">R_{McFadden}^2</code> @seealso <code>get.R2</code>
or <code class="reqn">PVAF</code> for the proportion of variance accounted for (<code class="reqn">PVAF</code>) @seealso <code>get.PVAF</code>.
Only when <code>method = "Hull"</code> works and default = <code>"PVAF"</code>. See details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Logical indicating to print iterative information or not. Default is <code>TRUE</code></p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>An object of class <code>validation</code> is a <code>list</code> containing the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>Q.orig</code></td>
<td>
<p>The original Q-matrix that maybe contains some mis-specifications and need to be validate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Q.sug</code></td>
<td>
<p>The Q-matrix that suggested by certain validation method.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>priority</code></td>
<td>
<p>An <code>I</code> × <code>K</code> matrix that contains the priority of every attribute for
each item. Only when the <code>search.method</code> is <code>"PAA"</code>, the value is availble. See details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Hull.fit</code></td>
<td>
<p>A <code>list</code> containing all the information needed to plot the Hull plot, which is available only when <code>method</code> = <code>"Hull"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iter</code></td>
<td>
<p>The number of iteration.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>time.cost</code></td>
<td>
<p>The time that CPU cost to finish the function.</p>
</td>
</tr>
</table>
<h3>The GDI method</h3>

<p>The GDI method (de la Torre &amp; Chiu, 2016), as the first Q-matrix validation method
applicable to saturated models, serves as an important foundation for various mainstream
Q-matrix validation methods.
</p>
<p>The method calculates the proportion of variance accounted for (<code class="reqn">PVAF</code>; @seealso <code>get.PVAF</code>)
for all possible q-vectors for each item, selects the q-vector with a <code class="reqn">PVAF</code> just
greater than the cut-off point (or Epsilon, EPS) as the correction result, and the variance
<code class="reqn">\zeta^2</code> is the generalized discriminating index (GDI; de la Torre &amp; Chiu, 2016).
Therefore, the GDI method is also considered as a generalized extension of the <code class="reqn">delta</code>
method (de la Torre, 2008), which also takes maximizing discrimination as its basic idea.
In the GDI method, <code class="reqn">\zeta^2</code> is defined as the weighted variance of the correct
response probabilities across all mastery patterns, that is:
</p>
<p style="text-align: center;"><code class="reqn">
 \zeta^2 =
 \sum_{l=1}^{2^K} \pi_{l} {(P(X_{pi}=1|\mathbf{\alpha}_{l}) - P_{i}^{mean})}^2
</code>
</p>

<p>where <code class="reqn">\pi_{l}</code> represents the prior probability of mastery pattern <code class="reqn">l</code>;
<code class="reqn">P_{i}^{mean}=\sum_{k=1}^{K}\pi_{l}P(X_{pi}=1|\mathbf{\alpha}_{l})</code> is the weighted
average of the correct response probabilities across all attribute mastery patterns.
When the q-vector is correctly specified, the calculated <code class="reqn">\zeta^2</code> should be maximized,
indicating the maximum discrimination of the item. However, in reality, <code class="reqn">\zeta^2</code>
continues to increase when the q-vector is over-specified, and the more attributes that
are over-specified, the larger <code class="reqn">\zeta^2</code> becomes. The q-vector with all attributes set
to 1 (i.e., <code class="reqn">\mathbf{q}_{1:K}</code>) has the largest <code class="reqn">\zeta^2</code> (de la Torre, 2016).
This is because an increase in attributes in the q-vector leads to an increase in item
parameters, resulting in greater differences in correct response probabilities across
attribute patterns and, consequently, increased variance. However, this increase in
variance is spurious. Therefore, de la Torre et al. calculated <code class="reqn">PVAF = \frac{\zeta^2}{\zeta_{1:K}^2}</code>
to describe the degree to which the discrimination of the current q-vector explains
the maximum discrimination. They selected an appropriate <code class="reqn">PVAF</code> cut-off point to achieve
a balance between q-vector fit and parsimony. According to previous studies,
the <code class="reqn">PVAF</code> cut-off point is typically set at 0.95 (Ma &amp; de la Torre, 2020; Najera et al., 2021).
</p>


<h3>The Wald method</h3>

<p>The Wald method (Ma &amp; de la Torre, 2020) combines the Wald test with <code class="reqn">PVAF</code> to correct
the Q-matrix at the item level. Its basic logic is as follows: when correcting item <code class="reqn">i</code>,
the single attribute that maximizes the <code class="reqn">PVAF</code> value is added to a vector with all
attributes set to <code class="reqn">\mathbf{0}</code> (i.e., <code class="reqn">\mathbf{q} = (0, 0, \ldots, 0)</code>) as a starting point.
In subsequent iterations, attributes in this vector are continuously added or
removed through the Wald test. The correction process ends when the <code class="reqn">PVAF</code> exceeds the
cut-off point or when no further attribute changes occur. The Wald statistic follows an
asymptotic <code class="reqn">\chi^{2}</code> distribution with a degree of freedom of <code class="reqn">2^{K^\ast} - 1</code>.
</p>
<p>The calculation method is as follows:
</p>
<p style="text-align: center;"><code class="reqn">
   Wald = (\mathbf{R} \times P_{i}(\mathbf{\alpha}))^{'}
   (\mathbf{R} \times \mathbf{V}_{i} \times \mathbf{R})^{-1}
   (\mathbf{R} \times P_{i}(\mathbf{\alpha}))
</code>
</p>

<p><code class="reqn">\mathbf{R}</code> represents the restriction matrix; <code class="reqn">P_{i}(\mathbf{\alpha})</code> denotes
the vector of correct response probabilities for item <code class="reqn">i</code>; <code class="reqn">\mathbf{V}_i</code> is the
variance-covariance matrix of the correct response probabilities for item <code class="reqn">i</code>, which
can be obtained by multiplying the <code class="reqn">\mathbf{M}_i</code> matrix (de la Torre, 2011) with the
variance-covariance matrix of item parameters <code class="reqn">\mathbf{\Sigma}_i</code>, i.e.,
<code class="reqn">\mathbf{V}_i = \mathbf{M}_i \times \mathbf{\Sigma}_i</code>. The <code class="reqn">\mathbf{\Sigma}_i</code> can be
derived by inverting the information matrix. Using the the empirical cross-product information
matrix (de la Torre, 2011) to calculate <code class="reqn">\mathbf{\Sigma}_i</code>.
</p>
<p><code class="reqn">\mathbf{M}_i</code> is a <code class="reqn">2^{K^\ast} × 2^{K^\ast}</code> matrix that represents the relationship between
the parameters of item <code class="reqn">i</code> and the attribute mastery patterns. The rows represent different mastery
patterns, while the columns represent different item parameters.
</p>


<h3>The Hull method</h3>

<p>The Hull method (Najera et al., 2021) addresses the issue of the cut-off point in the GDI
method and demonstrates good performance in simulation studies. Najera et al. applied the
Hull method for determining the number of factors to retain in exploratory factor analysis
(Lorenzo-Seva et al., 2011) to the retention of attribute quantities in the q-vector, specifically
for Q-matrix validation. The Hull method aligns with the GDI approach in its philosophy
of seeking a balance between fit and parsimony. While GDI relies on a preset, arbitrary
cut-off point to determine this balance, the Hull method utilizes the most pronounced elbow
in the Hull plot to make this judgment. The the most pronounced elbow is determined using
the following formula:
</p>
<p style="text-align: center;"><code class="reqn">
   st = \frac{(f_k - f_{k-1}) / (np_k - np_{k-1})}{(f_{k+1} - f_k) / (np_{k+1} - np_k)}
</code>
</p>

<p>where <code class="reqn">f_k</code> represents the fit-index value (can be <code class="reqn">PVAF</code> @seealso <code>get.PVAF</code> or
<code class="reqn">R2</code> @seealso <code>get.R2</code>) when the q-vector contains <code class="reqn">k</code> attributes,
similarly, <code class="reqn">f_{k-1}</code> and <code class="reqn">f_{k+1}</code> represent the fit-index value when the q-vector contains <code class="reqn">k-1</code>
and <code class="reqn">k+1</code> attributes, respectively. <code class="reqn">{np}_k</code> denotes the number of parameters when the
q-vector has <code class="reqn">k</code> attributes, which is <code class="reqn">2^k</code> for a saturated model. Likewise, <code class="reqn">{np}_{k-1}</code>
and <code class="reqn">{np}_{k+1}</code> represent the number of parameters when the q-vector has <code class="reqn">k-1</code> and
<code class="reqn">k+1</code> attributes, respectively. The Hull method calculates the <code class="reqn">st</code> index for all possible q-vectors
and retains the q-vector with the maximum <code class="reqn">st</code> index as the corrected result.
Najera et al. (2021) removed any concave points from the Hull plot, and when only the first and
last points remained in the plot, the saturated q-vector was selected.
</p>


<h3>The MLR-B method</h3>

<p>The MLR-B method proposed by Tu et al. (2022) differs from the GDI, Wald and Hull method in that
it does not employ <code class="reqn">PVAF</code>. Instead, it directly uses the marginal probabilities of attribute mastery for
subjects to perform multivariate logistic regression on their observed scores. This approach assumes
all possible q-vectors and conducts <code class="reqn">2^K-1</code> regression modelings. After proposing regression equations
that exclude any insignificant regression coefficients, it selects the q-vector corresponding to
the equation with the minimum AIC fit as the validation result. The performance of this method in both the
LCDM and GDM models even surpasses that of the Hull method, making it an efficient and reliable
approach for Q-matrix correction.
</p>


<h3>Iterative procedure</h3>

<p>The iterative procedure that one item modification at a time is item level iteration (<code>"item"</code>) in (Najera
et al., 2020, 2021), while the iterative procedure that the entire Q-matrix is modified at each iteration
is test level iteration (<code>"test"</code>) (Najera et al., 2020; Tu et al., 2022).
</p>
<p>The steps of the <code>item</code> level iterative procedure algorithm are as follows:
</p>

<dl>
<dt>Step1</dt>
<dd>
<p>Fit the <code>CDM</code> according to the item responses and the provisional Q-matrix (<code class="reqn">\mathbf{Q}^0</code>).</p>
</dd>
<dt>Step2</dt>
<dd>
<p>Validate the provisional Q-matrix and gain a suggested Q-matrix (<code class="reqn">\mathbf{Q}^1</code>).</p>
</dd>
<dt>Step3</dt>
<dd>
<p>for each item, <code class="reqn">PVAF_{0i}</code> as the <code class="reqn">PVAF</code> of the provisional q-vector specified in <code class="reqn">\mathbf{Q}^0</code>,
and <code class="reqn">PVAF_{1i}</code> as the <code class="reqn">PVAF</code> of the suggested q-vector in <code class="reqn">\mathbf{Q}^1</code>.</p>
</dd>
<dt>Step4</dt>
<dd>
<p>Calculate all items' <code class="reqn">\delta PVAF_{i}</code>, defined as <code class="reqn">\delta PVAF_{i} = |PVAF_{1i} - PVAF_{0i}|</code></p>
</dd>
<dt>Step5</dt>
<dd>
<p>Define the hit item as the item with the highest <code class="reqn">\delta PVAF_{i}</code>.</p>
</dd>
<dt>Step6</dt>
<dd>
<p>Update <code class="reqn">\mathbf{Q}^0</code> by changing the provisional q-vector by the suggested q-vector of the hit item.</p>
</dd>
<dt>Step7</dt>
<dd>
<p>Iterate over Steps 1 to 6 until <code class="reqn">\sum_{i=1}^{I} \delta PVAF_{i} = 0</code></p>
</dd>
</dl>
<p>The steps of the <code>test</code> level iterative procedure algorithm are as follows:
</p>

<dl>
<dt>Step1</dt>
<dd>
<p>Fit the <code>CDM</code> according to the item responses and the provisional Q-matrix (<code class="reqn">\mathbf{Q}^0</code>).</p>
</dd>
<dt>Step2</dt>
<dd>
<p>Validate the provisional Q-matrix and gain a suggested Q-matrix (<code class="reqn">\mathbf{Q}^1</code>).</p>
</dd>
<dt>Step3</dt>
<dd>
<p>Check whether <code class="reqn">\mathbf{Q}^1 = \mathbf{Q}^0</code>. If <code>TRUE</code>, terminate the iterative algorithm.
If <code>FALSE</code>, Update <code class="reqn">\mathbf{Q}^0</code> as <code class="reqn">\mathbf{Q}^1</code>.</p>
</dd>
<dt>Step4</dt>
<dd>
<p>Iterate over Steps 1 and 3 until one of conditions as follows is satisfied: 1. <code class="reqn">\mathbf{Q}^1 =
                 \mathbf{Q}^0</code>; 2. Reach the max iteration (<code>maxitr</code>); 3. <code class="reqn">\mathbf{Q}^1</code> does not satisfy
the condition that an attribute is measured by one item at least.</p>
</dd>
</dl>
<h3>Search algorithm</h3>

<p>Three search algorithms are available: Exhaustive Search Algorithm (ESA), Sequential Search Algorithm (SSA), 
and Priority Attribute Algorithm (PAA). 
ESA is a brute-force algorithm. When validating the q-vector of a particular item, it traverses all possible 
q-vectors and selects the most appropriate one based on the chosen Q-matrix validation method. Since there are 
<code class="reqn">2^{K-1}</code> possible q-vectors with <code class="reqn">K</code> attributes, ESA requires <code class="reqn">2^{K-1}</code> searches.
</p>
<p>SSA reduces the number of searches by adding one attribute at a time to the q-vector in a stepwise manner. 
Therefore, in the worst-case scenario, SSA requires <code class="reqn">K(K-1)/2</code> searches.
The detailed steps are as follows:
</p>

<dl>
<dt>Step 1</dt>
<dd>
<p>Define an empty q-vector <code class="reqn">\mathbf{q}^0=[00...0]</code> of length <code class="reqn">K</code>, 
where all elements are 0.</p>
</dd>
<dt>Step 2</dt>
<dd>
<p>Examine all single-attribute q-vectors, which are those formed by 
changing one of the 0s in <code class="reqn">\mathbf{q}^0</code> to 1. 
According to the criteria of the chosen Q-matrix validation method, 
select the optimal single-attribute q-vector, denoted as <code class="reqn">\mathbf{q}^1</code>.</p>
</dd>
<dt>Step 3</dt>
<dd>
<p>Examine all two-attribute q-vectors, which are those formed by changing 
one of the 0s in <code class="reqn">\mathbf{q}^1</code> to 1. According to the criteria of the 
chosen Q-matrix validation method, select the optimal two-attribute q-vector, 
denoted as <code class="reqn">\mathbf{q}^2</code>.</p>
</dd>
<dt>Step 4</dt>
<dd>
<p>Repeat this process until <code class="reqn">\mathbf{q}^K</code> is found, or the stopping criterion 
of the chosen Q-matrix validation method is met.</p>
</dd>
</dl>
<p>PAA is a highly efficient and concise algorithm that evaluates whether each attribute needs to be included in the 
q-vector based on the priority of the attributes. @seealso <code>get.priority</code>. Therefore, even in the worst-case scenario, PAA only requires 
<code class="reqn">K</code> searches.
The detailed process is as follows:
</p>

<dl>
<dt>Step 1</dt>
<dd>
<p>Using the applicable CDM (e.g. the G-DINA model) to estimate the model parameters 
and obtain the marginal attribute mastery probabilities matrix <code class="reqn">\mathbf{\Lambda}</code></p>
</dd>
<dt>Step 2</dt>
<dd>
<p>Use LASSO regression to calculate the priority of each attribute in the q-vector for item <code class="reqn">i</code></p>
</dd>
<dt>Step 3</dt>
<dd>
<p>Check whether each attribute is included in the optimal q-vector based on the attribute 
priorities from high to low seriatim and output the final suggested q-vector according to the 
criteria of the chosen Q-matrix validation method.</p>
</dd>
</dl>
<p>It should be noted that the Wald method proposed by Ma &amp; de la Torre (2020) uses a <code>"stepwise"</code> search approach. 
This approach involves incrementally adding or removing 1 from the q-vector and evaluating the significance of 
the change using the Wald test: 
1. If removing a 1 results in non-significance (indicating that the 1 is unnecessary), the 1 is removed from the q-vector; 
otherwise, the q-vector remains unchanged. 
2. If adding a 1 results in significance (indicating that the 1 is necessary), the 1 is added to the q-vector; 
otherwise, the q-vector remains unchanged.
The process stops when the q-vector no longer changes or when the PVAF reaches the preset cut-off point (i.e., 0.95).
</p>
<p>The <code>"forward"</code> search approach is another search method available for the Wald method, and its logic is simple because 
it merely keeps turning the 0s in the q vector into 1s, stopping when no more 0s can be turned into 1s or the PVAF 
reaches the cut-off point.
</p>
<p>Stepwise and Forward are unique search approach of the Wald method, and users should be aware of this. Since stepwise is 
inefficient and differs significantly from the extremely high efficiency of PAA, <code>Qval</code> also provides <code>PAA</code> 
for q-vector search in the Wald method. When applying the PAA version of the Wald method, the search still 
examines whether each attribute is necessary (by checking if the Wald test reaches significance after adding the attribute) 
according to attribute priority. The search stops when no further necessary attributes are found or when the 
PVAF reaches the preset cut-off point (i.e., 0.95).
</p>


<h3>Author(s)</h3>

<p>Haijiang Qin &lt;Haijiang133@outlook.com&gt;
</p>


<h3>References</h3>

<p>de la Torre, J., &amp; Chiu, C. Y. (2016). A General Method of Empirical Q-matrix Validation. Psychometrika, 81(2), 253-273. DOI: 10.1007/s11336-015-9467-8.
</p>
<p>de la Torre, J. (2008). An Empirically Based Method of Q-Matrix Validation for the DINA Model: Development and Applications. Journal of Education Measurement, 45(4), 343-362. DOI: 10.1111/j.1745-3984.2008.00069.x.
</p>
<p>Lorenzo-Seva, U., Timmerman, M. E., &amp; Kiers, H. A. (2011). The Hull method for selecting the number of common factors. Multivariate Behavioral Research, 46, 340–364. DOI: 10.1080/00273171.2011.564527.
</p>
<p>Ma, W., &amp; de la Torre, J. (2020). An empirical Q-matrix validation method for the sequential generalized DINA model. British Journal of Mathematical and Statistical Psychology, 73(1), 142-163. DOI: 10.1111/bmsp.12156.
</p>
<p>McFadden, D. (1974). Conditional logit analysis of qualitative choice behavior. In P. Zarembka (Ed.), Frontiers in economics (pp. 105–142). New York, NY: Academic Press.
</p>
<p>Najera, P., Sorrel, M. A., &amp; Abad, F. J. (2019). Reconsidering Cutoff Points in the General Method of Empirical Q-Matrix Validation. Educational and Psychological Measurement, 79(4), 727-753. DOI: 10.1177/0013164418822700.
</p>
<p>Najera, P., Sorrel, M. A., de la Torre, J., &amp; Abad, F. J. (2020). Improving Robustness in Q-Matrix Validation Using an Iterative and Dynamic Procedure. Applied Psychological Measurement, 44(6), 431-446. DOI: 10.1177/0146621620909904.
</p>
<p>Najera, P., Sorrel, M. A., de la Torre, J., &amp; Abad, F. J. (2021). Balancing fit and parsimony to improve Q-matrix validation. British Journal of Mathematical and Statistical Psychology, 74 Suppl 1, 110-130. DOI: 10.1111/bmsp.12228.
</p>
<p>Terzi, R., &amp; de la Torre, J. (2018). An Iterative Method for Empirically-Based Q-Matrix Validation. International Journal of Assessment Tools in Education, 248-262. DOI: 10.21449/ijate.40719.
</p>
<p>Tu, D., Chiu, J., Ma, W., Wang, D., Cai, Y., &amp; Ouyang, X. (2022). A multiple logistic regression-based (MLR-B) Q-matrix validation method for cognitive diagnosis models: A confirmatory approach. Behavior Research Methods. DOI: 10.3758/s13428-022-01880-x.
</p>


<h3>Examples</h3>

<pre><code class="language-R">################################################################
#                           Example 1                          #
#             The GDI method to validate Q-matrix              #
################################################################
set.seed(123)

library(Qval)

## generate Q-matrix and data
K &lt;- 4
I &lt;- 20
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ,
                         model = "GDINA", distribute = "horder")

## simulate random mis-specifications
example.MQ &lt;- sim.MQ(example.Q, 0.1)


## using MMLE/EM to fit CDM model first
example.CDM.obj &lt;- CDM(example.data$dat, example.MQ)

## using the fitted CDM.obj to avoid extra parameter estimation.
Q.GDI.obj &lt;- validation(example.data$dat, example.MQ, example.CDM.obj, method = "GDI")


## also can validate the Q-matrix directly
Q.GDI.obj &lt;- validation(example.data$dat, example.MQ)

## item level iteration
Q.GDI.obj &lt;- validation(example.data$dat, example.MQ, method = "GDI",
                        iter.level = "item", maxitr = 150)

## search method
Q.GDI.obj &lt;- validation(example.data$dat, example.MQ, method = "GDI",
                        search.method = "ESA")

## cut-off point
Q.GDI.obj &lt;- validation(example.data$dat, example.MQ, method = "GDI",
                        eps = 0.90)

## check QRR
print(zQRR(example.Q, Q.GDI.obj$Q.sug))




################################################################
#                           Example 2                          #
#             The Wald method to validate Q-matrix             #
################################################################
set.seed(123)

library(Qval)

## generate Q-matrix and data
K &lt;- 4
I &lt;- 20
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ, model = "GDINA",
                         distribute = "horder")

## simulate random mis-specifications
example.MQ &lt;- sim.MQ(example.Q, 0.1)


## using MMLE/EM to fit CDM first
example.CDM.obj &lt;- CDM(example.data$dat, example.MQ)

## using the fitted CDM.obj to avoid extra parameter estimation.
Q.Wald.obj &lt;- validation(example.data$dat, example.MQ, example.CDM.obj, method = "Wald")


## also can validate the Q-matrix directly
Q.Wald.obj &lt;- validation(example.data$dat, example.MQ, method = "Wald")

## check QRR
print(zQRR(example.Q, Q.Wald.obj$Q.sug))




################################################################
#                           Example 3                          #
#             The Hull method to validate Q-matrix             #
################################################################
set.seed(123)

library(Qval)

## generate Q-matrix and data
K &lt;- 4
I &lt;- 20
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ, model = "GDINA",
                         distribute = "horder")

## simulate random mis-specifications
example.MQ &lt;- sim.MQ(example.Q, 0.1)


## using MMLE/EM to fit CDM first
example.CDM.obj &lt;- CDM(example.data$dat, example.MQ)

## using the fitted CDM.obj to avoid extra parameter estimation.
Q.Hull.obj &lt;- validation(example.data$dat, example.MQ, example.CDM.obj, method = "Hull")


## also can validate the Q-matrix directly
Q.Hull.obj &lt;- validation(example.data$dat, example.MQ, method = "Hull")

## change PVAF to R2 as fit-index
Q.Hull.obj &lt;- validation(example.data$dat, example.MQ, method = "Hull", criter = "R2")

## check QRR
print(zQRR(example.Q, Q.Hull.obj$Q.sug))




################################################################
#                           Example 4                          #
#             The MLR-B method to validate Q-matrix            #
################################################################
set.seed(123)

library(Qval)

## generate Q-matrix and data
K &lt;- 4
I &lt;- 20
example.Q &lt;- sim.Q(K, I)
IQ &lt;- list(
  P0 = runif(I, 0.0, 0.2),
  P1 = runif(I, 0.8, 1.0)
)
example.data &lt;- sim.data(Q = example.Q, N = 500, IQ = IQ, model = "GDINA",
                         distribute = "horder")

## simulate random mis-specifications
example.MQ &lt;- sim.MQ(example.Q, 0.1)


## using MMLE/EM to fit CDM first
example.CDM.obj &lt;- CDM(example.data$dat, example.MQ)

## using the fitted CDM.obj to avoid extra parameter estimation.
Q.MLR.obj &lt;- validation(example.data$dat, example.MQ, example.CDM.obj, method = "MLR-B")


## also can validate the Q-matrix directly
Q.MLR.obj &lt;- validation(example.data$dat, example.MQ, method  = "MLR-B")

## check QRR
print(zQRR(example.Q, Q.Hull.obj$Q.sug))


</code></pre>


</div>