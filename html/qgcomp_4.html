<div class="container">

<table style="width: 100%;"><tr>
<td>qgcomp.glm.noboot</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Quantile g-computation for continuous, binary, and count outcomes under linearity/additivity</h2>

<h3>Description</h3>

<p>This function estimates a linear dose-response parameter representing a one quantile
increase in a set of exposures of interest. This function is limited to linear and additive
effects of individual components of the exposure. This model estimates the parameters of a marginal
structural model (MSM) based on g-computation with quantized exposures. Note: this function is
valid only under linear and additive effects of individual components of the exposure, but when
these hold the model can be fit with very little computational burden.
qgcomp.noboot is an equivalent function (slated for deprecation)
</p>


<h3>Usage</h3>

<pre><code class="language-R">qgcomp.glm.noboot(
  f,
  data,
  expnms = NULL,
  q = 4,
  breaks = NULL,
  id = NULL,
  weights,
  alpha = 0.05,
  bayes = FALSE,
  ...
)

qgcomp.noboot(
  f,
  data,
  expnms = NULL,
  q = 4,
  breaks = NULL,
  id = NULL,
  weights,
  alpha = 0.05,
  bayes = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>f</code></td>
<td>
<p>R style formula</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>data frame</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>expnms</code></td>
<td>
<p>character vector of exposures of interest</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>q</code></td>
<td>
<p>NULL or number of quantiles used to create quantile indicator variables
representing the exposure variables. If NULL, then gcomp proceeds with un-transformed
version of exposures in the input datasets (useful if data are already transformed,
or for performing standard g-computation)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>breaks</code></td>
<td>
<p>(optional) NULL, or a list of (equal length) numeric vectors that
characterize the minimum value of each category for which to
break up the variables named in expnms. This is an alternative to using 'q'
to define cutpoints.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>id</code></td>
<td>
<p>(optional) NULL, or variable name indexing individual units of
observation (only needed if analyzing data with multiple observations per
id/cluster). Note that qgcomp.glm.noboot will not produce cluster-appropriate
standard errors (this parameter is essentially ignored in qgcomp.glm.noboot).
qgcomp.glm.boot can be used for this, which will use bootstrap
sampling of clusters/individuals to estimate cluster-appropriate standard
errors via bootstrapping.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>"case weights" - passed to the "weight" argument of
<code>glm</code> or <code>bayesglm</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>alpha level for confidence limit calculation</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bayes</code></td>
<td>
<p>use underlying Bayesian model (<code>arm</code> package defaults). Results
in penalized parameter estimation that can help with very highly correlated
exposures. Note: this does not lead to fully Bayesian inference in general,
so results should be interpreted as frequentist.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>arguments to glm (e.g. family)</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>For continuous outcomes, under a linear model with no
interaction terms, this is equivalent to g-computation of the effect of
increasing every exposure by 1 quantile. For binary/count outcomes
outcomes, this yields a conditional log odds/rate ratio(s) representing the
change in the expected conditional odds/rate (conditional on covariates)
from increasing every exposure by 1 quantile. In general, the latter
quantity is not equivalent to g-computation estimates. Hypothesis test
statistics and confidence intervals are based on using the delta
estimate variance of a linear combination of random variables.
</p>


<h3>Value</h3>

<p>a qgcompfit object, which contains information about the effect
measure of interest (psi) and associated variance (var.psi), as well
as information on the model fit (fit) and information on the
weights/standardized coefficients in the positive (pos.weights) and
negative (neg.weights) directions.
</p>


<h3>See Also</h3>

<p>Other qgcomp_methods: 
<code>qgcomp.cch.noboot()</code>,
<code>qgcomp.cox.boot()</code>,
<code>qgcomp.cox.noboot()</code>,
<code>qgcomp.glm.boot()</code>,
<code>qgcomp.hurdle.boot()</code>,
<code>qgcomp.hurdle.noboot()</code>,
<code>qgcomp.multinomial.boot()</code>,
<code>qgcomp.multinomial.noboot()</code>,
<code>qgcomp.partials()</code>,
<code>qgcomp.zi.boot()</code>,
<code>qgcomp.zi.noboot()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(50)
# linear model
dat &lt;- data.frame(y=runif(50,-1,1), x1=runif(50), x2=runif(50), z=runif(50))
qgcomp.glm.noboot(f=y ~ z + x1 + x2, expnms = c('x1', 'x2'), data=dat, q=2, family=gaussian())
# not intercept model
qgcomp.glm.noboot(f=y ~-1+ z + x1 + x2, expnms = c('x1', 'x2'), data=dat, q=2, family=gaussian())
# logistic model
dat2 &lt;- data.frame(y=rbinom(50, 1,0.5), x1=runif(50), x2=runif(50), z=runif(50))
qgcomp.glm.noboot(f=y ~ z + x1 + x2, expnms = c('x1', 'x2'), data=dat2, q=2, family=binomial())
# poisson model
dat3 &lt;- data.frame(y=rpois(50, .5), x1=runif(50), x2=runif(50), z=runif(50))
qgcomp.glm.noboot(f=y ~ z + x1 + x2, expnms = c('x1', 'x2'), data=dat3, q=2, family=poisson())
# weighted model
N=5000
dat4 &lt;- data.frame(y=runif(N), x1=runif(N), x2=runif(N), z=runif(N))
dat4$w=runif(N)*2
qdata = quantize(dat4, expnms = c("x1", "x2"))$data
(qgcfit &lt;- qgcomp.glm.noboot(f=y ~ z + x1 + x2, expnms = c('x1', 'x2'), data=dat4, q=4,
                         family=gaussian(), weights=w))
qgcfit$fit
glm(y ~ z + x1 + x2, data = qdata, weights=w)
</code></pre>


</div>