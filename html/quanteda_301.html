<div class="container">

<table style="width: 100%;"><tr>
<td>tokens_compound</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Convert token sequences into compound tokens</h2>

<h3>Description</h3>

<p>Replace multi-token sequences with a multi-word, or "compound" token.  The
resulting compound tokens will represent a phrase or multi-word expression,
concatenated with <code>concatenator</code> (by default, the "<code style="white-space: pre;">⁠_⁠</code>" character) to form a
single "token".  This ensures that the sequences will be processed
subsequently as single tokens, for instance in constructing a dfm.
</p>


<h3>Usage</h3>

<pre><code class="language-R">tokens_compound(
  x,
  pattern,
  valuetype = c("glob", "regex", "fixed"),
  concatenator = concat(x),
  window = 0L,
  case_insensitive = TRUE,
  join = TRUE,
  keep_unigrams = FALSE,
  apply_if = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>an input tokens object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pattern</code></td>
<td>
<p>a character vector, list of character vectors, dictionary,
or collocations object.  See pattern for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>valuetype</code></td>
<td>
<p>the type of pattern matching: <code>"glob"</code> for "glob"-style
wildcard expressions; <code>"regex"</code> for regular expressions; or <code>"fixed"</code> for
exact matching. See valuetype for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>concatenator</code></td>
<td>
<p>character; the concatenation character that will connect
the tokens making up a multi-token sequence.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>window</code></td>
<td>
<p>integer; a vector of length 1 or 2 that specifies size of the
window of tokens adjacent to <code>pattern</code> that will be compounded with matches
to <code>pattern</code>.  The window can be asymmetric if two elements are specified,
with the first giving the window size before <code>pattern</code> and the second the
window size after.  If paddings (empty <code>""</code> tokens) are found, window will
be shrunk to exclude them.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>case_insensitive</code></td>
<td>
<p>logical; if <code>TRUE</code>, ignore case when matching a
<code>pattern</code> or dictionary values</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>join</code></td>
<td>
<p>if <code>TRUE</code>, join overlapping compounds into a single
compound; otherwise, form these separately.  See examples.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>keep_unigrams</code></td>
<td>
<p>if <code>TRUE</code>, keep the original tokens.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>apply_if</code></td>
<td>
<p>logical vector of length <code>ndoc(x)</code>; documents are modified
only when corresponding values are <code>TRUE</code>, others are left unchanged.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A tokens object in which the token sequences matching <code>pattern</code>
have been replaced by new compounded "tokens" joined by the concatenator.
</p>


<h3>Note</h3>

<p>Patterns to be compounded (naturally) consist of multi-word sequences,
and how these are expected in <code>pattern</code> is very specific.  If the elements
to be compounded are supplied as space-delimited elements of a character
vector, wrap the vector in <code>phrase()</code>.  If the elements to be compounded
are separate elements of a character vector, supply it as a list where each
list element is the sequence of character elements.
</p>
<p>See the examples below.
</p>


<h3>Examples</h3>

<pre><code class="language-R">txt &lt;- "The United Kingdom is leaving the European Union."
toks &lt;- tokens(txt, remove_punct = TRUE)

# character vector - not compounded
tokens_compound(toks, c("United", "Kingdom", "European", "Union"))

# elements separated by spaces - not compounded
tokens_compound(toks, c("United Kingdom", "European Union"))

# list of characters - is compounded
tokens_compound(toks, list(c("United", "Kingdom"), c("European", "Union")))

# elements separated by spaces, wrapped in phrase() - is compounded
tokens_compound(toks, phrase(c("United Kingdom", "European Union")))

# supplied as values in a dictionary (same as list) - is compounded
# (keys do not matter)
tokens_compound(toks, dictionary(list(key1 = "United Kingdom",
                                      key2 = "European Union")))
# pattern as dictionaries with glob matches
tokens_compound(toks, dictionary(list(key1 = c("U* K*"))), valuetype = "glob")

# note the differences caused by join = FALSE
compounds &lt;- list(c("the", "European"), c("European", "Union"))
tokens_compound(toks, pattern = compounds, join = TRUE)
tokens_compound(toks, pattern = compounds, join = FALSE)

# use window to form ngrams
tokens_remove(toks, pattern = stopwords("en")) |&gt;
    tokens_compound(pattern = "leav*", join = FALSE, window = c(0, 3))

</code></pre>


</div>